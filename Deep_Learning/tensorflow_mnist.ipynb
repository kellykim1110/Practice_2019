{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-fgeOCAaYUJ",
        "colab_type": "code",
        "outputId": "1a11dbde-8ad7-451d-c64c-f0b68cfa5b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist=input_data.read_data_sets(\"./mnist/data/\",one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-ec29c9341286>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUMMrbgHaoRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터를 넣을 공간인 placeholder 구성하기.\n",
        "# 데이터 개수는 값을 정해주지 않고 열어두는 의미로 None\n",
        "# conv2d는 2d 데이터를 받으므로 2d 형태로 28*28,\n",
        "# 흑백 이미지이므로 channel = 1\n",
        "X=tf.placeholder(tf.float32,[None,28,28,1])\n",
        "# 데이터 개수는 오픈해두는 의미로 None\n",
        "# label 즉, target값이 0~9까지 숫자 이므로 10개의 클래스\n",
        "Y=tf.placeholder(tf.float32,[None,10])\n",
        "\n",
        "\n",
        "\n",
        "keep_prob=tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYg-WUsnbTCw",
        "colab_type": "code",
        "outputId": "7c46c815-1ca5-47f2-f85e-3ceead427700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 첫 번째 레이어의 필터를 랜덤 정규화(표준편차 0.01)한 값으로 넣기\n",
        "# 필터 : 5*5 사이즈, input이 흑백인 채널이므로 채널수는 1, 20개의 필터를 만들겠다.\n",
        "W1=tf.Variable(tf.random_normal([5,5,1,20],stddev=0.01))\n",
        "# convolution layer 1 만들기\n",
        "# layer1은 입력으로 X를 받고 필터 W1을 사용하고\n",
        "# stride = [샘플수, 세로 길이, 가로 길이, 채널 수]\n",
        "# padding='SAME' : 추가 패딩은 넣지 않음(사이즈 그대로)\n",
        "L1=tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding=\"SAME\")\n",
        "L1=tf.nn.relu(L1)\n",
        "\n",
        "print(L1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu:0\", shape=(?, 28, 28, 20), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZTmfl_ocvH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 첫 번째 convolution layer 에 Pooling Layer(크기를 줄여주는 레이어) 적용하기\n",
        "# 입력 :이전 Layer\n",
        "# ksize = [샘플 수, 세로 사이즈, 가로 사이즈, 채널 수]\n",
        "# :pooling layer에서의 필터의 사이즈를 의미\n",
        "# strides = [샘플 수, 세로 스트라이드, 가로 스트라이드, 채널 수]\n",
        "# :polling layer에서의 필터의 움직임을 의미\n",
        "# strides 는 가로 세로 각각 1로 하자.\n",
        "# padding = 'SAME' : 사이즈 유지\n",
        "L1=tf.nn.max_pool(L1,ksize=[1,4,4,1],strides=[1,4,4,1],padding=\"SAME\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fIAyg70dIko",
        "colab_type": "code",
        "outputId": "63bf400f-c311-43c9-adb5-3b550bd3cb44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(L1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool:0\", shape=(?, 7, 7, 20), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG5i5PNCdL2g",
        "colab_type": "code",
        "outputId": "1efe0eb1-5a61-4d76-a624-6fc762878f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "W2=tf.Variable(tf.random_normal([5,5,20,53],stddev=0.01))\n",
        "\n",
        "L2=tf.nn.conv2d(L1,W2,strides=[1,1,1,1],padding=\"SAME\")\n",
        "L2=tf.nn.relu(L2)\n",
        "\n",
        "print(L2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_1:0\", shape=(?, 7, 7, 53), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy4rarxHd4JT",
        "colab_type": "code",
        "outputId": "e1298a96-5410-484a-82c1-acd6ef1f5365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding='SAME')\n",
        "print(L2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool_1:0\", shape=(?, 4, 4, 53), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElGii7BQd-HQ",
        "colab_type": "code",
        "outputId": "10238b84-894b-431c-8f78-a481d77a6997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# 세 번째 레이어(Fully Connected Layer)\n",
        "# reshape와 행렬곱을 적용함\n",
        "\n",
        "# 20개의 필터를 만들겠다.\n",
        "# 필터를 랜덤 정규화(표준편차 0.01)한 값으로 넣기\n",
        "# 1차원으로 펴주는 flatten 작용이 들어가므로 [4, 4, 53, 20]으로 들어가지 않는다.\n",
        "# 앞단 필터의 가중치의 갯수, 현재 적용하고자하는 필터의 갯수\n",
        "W3=tf.Variable(tf.random_normal([4*4*53,20],stddev=0.01))\n",
        "# reshape 과정이 들어간다.\n",
        "# -1은 몇개의 데이터가 들어올지 모르므로 열어두는 역할\n",
        "# 뒤에 값은 앞단 필터의 가중치의 갯수\n",
        "L3=tf.reshape(L2,[-1,4*4*53])\n",
        "#행렬곱\n",
        "L3=tf.matmul(L3,W3)\n",
        "# 엑티베이션 펑션으로 relu 사용\n",
        "L3=tf.nn.relu(L3)\n",
        "# dropout 을 통해 과적합을 줄여주자.\n",
        "L3 = tf.nn.dropout(L3,keep_prob)\n",
        "print(L3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-d3cd285d0a0a>:11: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"dropout/mul_1:0\", shape=(?, 20), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GdmReQDfV5f",
        "colab_type": "code",
        "outputId": "03d18bb1-caec-4407-b855-6765e8da0117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 마지막 레이어(Flatten Layer)\n",
        "# 필터를 랜덤 정규화(표준편차 0.01)한 값으로 넣기\n",
        "# 앞단 필터의 갯수, 현재 적용하고자 하는 필터수를 리스트로 넣어준다.\n",
        "# 현재 얻고자 하는 필터수는 10개의 숫자 값이므로 10\n",
        "W4=tf.Variable(tf.random_normal([20,10],stddev=0.01))\n",
        "\n",
        "model=tf.matmul(L3,W4)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MatMul_1:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY0Pgw9uf2YW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer=tf.train.AdamOptimizer(0.001).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj3Ua-Bkgvct",
        "colab_type": "code",
        "outputId": "0948da6d-55ae-4443-b061-d8dca534eb84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "sess=tf.Session()\n",
        "init=tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "# batch_size를 500으로 설정해보자.\n",
        "batch_size=500\n",
        "total_batch=int(mnist.train.num_examples/batch_size)\n",
        "\n",
        "for epoch in range(0,3):\n",
        "  %%time\n",
        "  total_loss = 0\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    # 이미지 데이터를 CNN 모델을 위한 자료형태인 [28 28 1] 의 형태로 재구성합니다.\n",
        "    batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
        "    _, loss_val = sess.run([optimizer, loss],\n",
        "                            feed_dict={X: batch_xs,Y: batch_ys, keep_prob: 0.7})\n",
        "\n",
        "    total_loss += loss_val\n",
        "  print('Epoch:', '%04d' % (epoch + 1),\n",
        "        'Avg. loss =', '{:.3f}'.format(total_loss / total_batch))\n",
        "print('최적화 완료!')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.44 µs\n",
            "Epoch: 0001 Avg. loss = 1.474\n",
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 6.68 µs\n",
            "Epoch: 0002 Avg. loss = 0.701\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.44 µs\n",
            "Epoch: 0003 Avg. loss = 0.505\n",
            "최적화 완료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEjpGt7ejcOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}